{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727ee378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import gdcm\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002bdb1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19f4b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2538"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"D:\\Breast_Cancer_Detection\\train_images\\dicom13\\*\\*.dcm\"\n",
    "train_images = glob.glob(path)\n",
    "len(train_images)  # 54706"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04f860",
   "metadata": {},
   "source": [
    "# Crop image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dffdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, show=True):\n",
    "    # Binarize the image\n",
    "    bin_pixels = cv2.threshold(img, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "   \n",
    "    # Make contours around the binarized image, keep only the largest contour\n",
    "    contours, _ = cv2.findContours(bin_pixels, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a mask from the largest contour\n",
    "    mask = np.zeros(img.shape, np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)\n",
    "   \n",
    "    # Use bitwise_and to get masked part of the original image\n",
    "    out = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    # get bounding box of contour\n",
    "    y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])\n",
    "    x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])\n",
    "    \n",
    "    x1 = int(0.99 * x1)\n",
    "    x2 = int(1.01 * x2)\n",
    "    y1 = int(0.99 * y1)\n",
    "    y2 = int(1.01 * y2)\n",
    "    \n",
    "    if show:\n",
    "        plt.imshow(out[y1:y2, x1:x2], cmap=\"gray\") ; \n",
    "\n",
    "    return out[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220cb529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9092a54c734d92b6c541177fa91220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "patient 10011\n",
      "\n",
      "==========================================================================================\n",
      "patient 10011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(train_images[5:7]):\n",
    "    print(90*\"=\")\n",
    "    patient = f.split('\\\\')[-2]\n",
    "    image = f.split('\\\\')[-1][:-4]\n",
    "    \n",
    "    print(f\"patient {patient}\\n\")\n",
    "    \n",
    "    dicom = pydicom.dcmread(f)\n",
    "    img = dicom.pixel_array\n",
    "\n",
    "    img = (img - img.min()) / (img.max() - img.min())    \n",
    "    img *= 255\n",
    "    img = np.uint8(img)\n",
    "\n",
    "    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = 1 - img\n",
    "\n",
    "    #plt.figure(figsize=(5, 5))\n",
    "    #plt.imshow(img, cmap=\"gray\")\n",
    "    #plt.title(f\"original image for {patient} {image}\")\n",
    "    #plt.show()\n",
    "        \n",
    "    img = crop_image(img, show=False)\n",
    "    \n",
    "    #plt.figure(figsize=(5, 5))\n",
    "    #plt.imshow(img, cmap=\"gray\")\n",
    "    #plt.title(f\"after text removal / cropping {patient} {image}\")\n",
    "    #plt.show()\n",
    "    \n",
    "    crop_image(img, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3dbe3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Resize 512,256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b633bfdc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cba8182978c45c6bd0f752679ef2007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m      6\u001b[0m dicom \u001b[38;5;241m=\u001b[39m pydicom\u001b[38;5;241m.\u001b[39mdcmread(f)\n\u001b[1;32m----> 7\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mdicom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpixel_array\u001b[49m\n\u001b[0;32m      9\u001b[0m img \u001b[38;5;241m=\u001b[39m (img \u001b[38;5;241m-\u001b[39m img\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (img\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m img\u001b[38;5;241m.\u001b[39mmin())\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dicom\u001b[38;5;241m.\u001b[39mPhotometricInterpretation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMONOCHROME1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\AI\\lib\\site-packages\\pydicom\\dataset.py:1887\u001b[0m, in \u001b[0;36mDataset.pixel_array\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpixel_array\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1874\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the pixel data as a :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[0;32m   1875\u001b[0m \n\u001b[0;32m   1876\u001b[0m \u001b[38;5;124;03m    .. versionchanged:: 1.4\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1885\u001b[0m \u001b[38;5;124;03m        :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1887\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_pixel_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\AI\\lib\\site-packages\\pydicom\\dataset.py:1444\u001b[0m, in \u001b[0;36mDataset.convert_pixel_data\u001b[1;34m(self, handler_name)\u001b[0m\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_pixel_data_using_handler(handler_name)\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_pixel_data_without_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\AI\\lib\\site-packages\\pydicom\\dataset.py:1536\u001b[0m, in \u001b[0;36mDataset._convert_pixel_data_without_handler\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m available_handlers:\n\u001b[0;32m   1535\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1536\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_pixel_data_conversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1537\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\AI\\lib\\site-packages\\pydicom\\dataset.py:1563\u001b[0m, in \u001b[0;36mDataset._do_pixel_data_conversion\u001b[1;34m(self, handler)\u001b[0m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;124;03m\"\"\"Do the actual data conversion using the given handler.\"\"\"\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;66;03m# Use the handler to get a 1D numpy array of the pixel data\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;66;03m# Will raise an exception if no pixel data element\u001b[39;00m\n\u001b[1;32m-> 1563\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pixeldata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array \u001b[38;5;241m=\u001b[39m reshape_pixel_array(\u001b[38;5;28mself\u001b[39m, arr)\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;66;03m# Some handler/transfer syntax combinations may need to\u001b[39;00m\n\u001b[0;32m   1567\u001b[0m \u001b[38;5;66;03m#   convert the color space from YCbCr to RGB\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\AI\\lib\\site-packages\\pydicom\\pixel_data_handlers\\gdcm_handler.py:247\u001b[0m, in \u001b[0;36mget_pixeldata\u001b[1;34m(ds)\u001b[0m\n\u001b[0;32m    245\u001b[0m     gdcm_data_element \u001b[38;5;241m=\u001b[39m create_data_element(ds)\n\u001b[0;32m    246\u001b[0m     gdcm_image \u001b[38;5;241m=\u001b[39m create_image(ds, gdcm_data_element)\n\u001b[1;32m--> 247\u001b[0m     pixel_str \u001b[38;5;241m=\u001b[39m \u001b[43mgdcm_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetBuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     pixel_str \u001b[38;5;241m=\u001b[39m _get_pixel_str_fileio(ds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Load dcm\n",
    "for f in tqdm(train_images[::]):\n",
    "    patient = f.split('\\\\')[-2]\n",
    "    image = f.split('\\\\')[-1][:-4]\n",
    "\n",
    "    dicom = pydicom.dcmread(f)\n",
    "    img = dicom.pixel_array\n",
    "\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = 1 - img\n",
    "        \n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #plt.imshow(img, cmap=\"gray\")\n",
    "    #plt.title(f\"{patient} {image}\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa757d0d",
   "metadata": {},
   "source": [
    "### Remove letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88905227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_charater(f,size = (512,512),save_folder=\"\"):\n",
    "    for f in tqdm(train_images[::]):\n",
    "        patient = f.split('\\\\')[-2]\n",
    "        image = f.split('\\\\')[-1][:-4]\n",
    "    \n",
    "        dicom = pydicom.dcmread(f)\n",
    "        pixels = dicom.pixel_array\n",
    "\n",
    "        if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            pixels = np.amax(pixels) - pixels\n",
    "        else:\n",
    "            pixels = pixels - np.min(pixels)\n",
    "        \n",
    "        if np.max(pixels) != 0:\n",
    "            pixels = pixels / np.max(pixels)\n",
    "            pixels = (pixels * 255).astype(np.uint8)\n",
    "        # Binarize the image\n",
    "        bin_pixels = cv2.threshold(pixels, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        # Make contours around the binarized image, keep only the largest contour\n",
    "        contours, _ = cv2.findContours(bin_pixels, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Create a mask from the largest contour\n",
    "        mask = np.zeros(pixels.shape, np.uint8)\n",
    "        cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)\n",
    "\n",
    "        # Use bitwise_and to get masked part of the original image\n",
    "        out = cv2.bitwise_and(pixels,mask)\n",
    "        cv2.imwrite(save_folder + f\"{patient}_{image}.png\",cv2.resize(out,size))\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c1cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FOLDER = \"output/\"\n",
    "SIZE = (512,512)\n",
    "EXTENSION = \"png\"\n",
    "\n",
    "#os.makedirs(SAVE_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13816135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040d62e8ecdf4dc0a9ff46851b2e4b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = Parallel(n_jobs=4)(\n",
    "    delayed(remove_charater)(uid, size=SIZE, save_folder=SAVE_FOLDER)\n",
    "    for uid in tqdm(train_images[:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e590c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
